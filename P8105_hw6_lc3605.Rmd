---
title: "Homework #6"
author: "Lynn Chen"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(modelr)
library(readxl)
library(ggplot2)


knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1: 

```{r load and clean the data}
birthweight = read_csv("./data/birthweight.csv")

## Clean the data 

birthweight = birthweight %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = factor(babysex, levels = c("1", "2")),
    babysex = fct_recode(babysex, "Female" = "2", "Male" = "1"),
    frace = factor(frace, 
                       levels = c("1", "2", "3", "4", "5", "6", "7", "8", "9")),
    frace = fct_recode(frace, 
                       "White" = "1",
                       "Black" = "2",
                       "Asian" = "3",
                       "Puerto Rican" = "4", 
                       "Other" = "8",
                       "Unknown" = "9"),
    malform = factor(malform, labels = c("Absent", "Present")),
    mrace = factor(mrace,  c(1, 2, 3, 4, 8)),
    mrace = fct_recode(mrace, 
                       "White" = "1",
                       "Black" = "2",
                       "Asian" = "3",
                       "Puerto Rican" = "4", 
                       "Other" = "8"))

## check for missing values
apply(is.na(birthweight),2,sum)
sum(!complete.cases(birthweight))

```

* This dataset contains `r nrow(birthweight)` rows and `r ncol(birthweight)` columns. 
There are no missing values in the data!! YAY!    


For the regression model, in order to choose more meaningful set of predictors for the ultimal model I use stepwise regression with backward selection.

```{r stepwise}
model_1 = 
  lm(bwt ~ ., data = birthweight) %>% 
  step(direction = "backward", trace = 0) %>% 
  broom::tidy() %>% 
  knitr::kable()
```

The chosen model include predictors:`babysex`, `bhead`, `blength`, `delwt`, `fincome`, `gaweeks`, `mheight`, `mrace`, `parity`, `ppwt`, and `smoken`. 

```{r fit model}
fit = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + mheight + mrace + parity + ppwt + smoken, data = birthweight) 
summary(fit)

birthweight %>% 
    add_predictions(fit) %>% 
    add_residuals(fit) %>% 
    ggplot(aes(x = pred, y = resid)) +
    geom_point(alpha = 0.2)  + 
    geom_smooth(se = F, color = "red", method = "lm", size = 1, linetype = 2) + 
    labs(title = "Residuals vs. Predicted Values", 
       x = "Predicted", 
       y = "Residuals")
```

According to the residuals against fitted values plot, the residuals are roughly symmetrical around y = 0. The residuals seems to be evenly distributed and the normal distribution of residuals assumption is satisfied for linear regression. There are a few data points with low fitted values and high residuals, majority of data points cluster around predicted values 2500 - 4000.

### Compare models

* **Model 2**: bwt ~ blength + gaweeks

* **Model 3**: bwt ~ babysex + blength + bhead + babysex * blength + babysex * bhead + blength * bhead + babysex * blength * bhead

```{r}
model_2 = 
  lm(bwt ~ blength + gaweeks, data = birthweight) %>% 
  broom::tidy() %>% 
  knitr::kable()

model_3 = 
  lm(bwt ~ babysex * blength * bhead, data = birthweight) %>% 
  broom::tidy() %>% 
  knitr::kable()

```


  


